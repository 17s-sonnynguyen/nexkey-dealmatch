{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e21d1012-8ca3-4c47-bd07-a969e90d71ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df88f8e9-c085-419f-9664-66d76d6e25ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data/nexkey_synthetic_dataset_v1\"\n",
    "\n",
    "queries = pd.read_csv(f\"{DATA_PATH}/queries.csv\")\n",
    "properties = pd.read_csv(f\"{DATA_PATH}/properties.csv\")\n",
    "interactions = pd.read_csv(f\"{DATA_PATH}/interactions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9de3d68-a74c-4128-a149-56ba862678dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_FEATURES = [\n",
    "    \"beds_min\",\n",
    "    \"baths_min\",\n",
    "    \"sqft_min\",\n",
    "    \"purchase_price_max\",\n",
    "    \"arv_min\",\n",
    "    \"entry_fee_max\",\n",
    "    \"monthly_payment_max\",\n",
    "]\n",
    "\n",
    "PROPERTY_FEATURES = [\n",
    "    \"beds\",\n",
    "    \"baths\",\n",
    "    \"sqft\",\n",
    "    \"purchase_price\",\n",
    "    \"arv\",\n",
    "    \"entry_fee\",\n",
    "    \"estimated_monthly_payment\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbad56cd-8f94-44f4-b419-1de67a104ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: (480000, 14)\n",
      "Labels shape: (480000,)\n"
     ]
    }
   ],
   "source": [
    "# Merge query info\n",
    "data = interactions.merge(\n",
    "    queries[[\"query_id\"] + QUERY_FEATURES],\n",
    "    on=\"query_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Merge property info\n",
    "data = data.merge(\n",
    "    properties[[\"property_id\"] + PROPERTY_FEATURES],\n",
    "    on=\"property_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Target variable\n",
    "labels = data[\"relevance\"].values.astype(np.float32)\n",
    "\n",
    "# Final feature matrix\n",
    "features = data[QUERY_FEATURES + PROPERTY_FEATURES].values.astype(np.float32)\n",
    "\n",
    "print(\"Feature shape:\", features.shape)\n",
    "print(\"Labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c360ea35-7461-4a94-b1e2-7cb098a9c187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled features shape: (480000, 14)\n",
      "Scaler saved to ../models/checkpoints/numeric_scaler.joblib\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# 1) Fit scaler on training features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features).astype(np.float32)\n",
    "\n",
    "# 2) Save the scaler so Step 3 can use the SAME scaling\n",
    "os.makedirs(\"../models/checkpoints\", exist_ok=True)\n",
    "joblib.dump(scaler, \"../models/checkpoints/numeric_scaler.joblib\")\n",
    "\n",
    "print(\"Scaled features shape:\", features_scaled.shape)\n",
    "print(\"Scaler saved to ../models/checkpoints/numeric_scaler.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa4572f0-14f1-4e76-9580-c43d06b8ca85",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DealMatchDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32b7862d-e52a-40ed-a1be-3e4911d8b3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DealMatchDataset(features_scaled, labels)\n",
    "\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "809bc8db-8fc5-48c5-9d28-b3b07ad5a499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class DealRanker(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1)  # one score\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fe3837c-3827-4f78-8347-06c6da9a012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DealRanker(input_dim=features.shape[1])\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c0b0f56-8aaa-4c0f-a883-acbc31d9e672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Loss: 1.0439\n",
      "Epoch 2/5 - Loss: 0.9990\n",
      "Epoch 3/5 - Loss: 0.9813\n",
      "Epoch 4/5 - Loss: 0.9658\n",
      "Epoch 5/5 - Loss: 0.9557\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for X_batch, y_batch in loader:\n",
    "        # 1. Forward pass\n",
    "        preds = model(X_batch)\n",
    "\n",
    "        # 2. Compute loss\n",
    "        loss = criterion(preds, y_batch)\n",
    "\n",
    "        # 3. Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ca81a6f-fa8b-4b8d-8690-4994eadc71e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Make sure the directory exists\n",
    "import os\n",
    "\n",
    "os.makedirs(\"../models/checkpoints\", exist_ok=True)\n",
    "\n",
    "# Save trained model\n",
    "torch.save(\n",
    "    model.state_dict(),\n",
    "    \"../models/checkpoints/numeric_ranker.pt\"\n",
    ")\n",
    "\n",
    "print(\"Model saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
