{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7ec9670-16ed-4c56-ac11-e83727c5c3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "117d19f2-6740-413c-a998-f041bc5720f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data + vocab + deal embeddings ✅\n",
      "deal_vecs: (15000, 128)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../data/nexkey_synthetic_dataset_v1\"\n",
    "\n",
    "queries = pd.read_csv(f\"{DATA_PATH}/queries.csv\")\n",
    "properties = pd.read_csv(f\"{DATA_PATH}/properties.csv\")\n",
    "interactions = pd.read_csv(f\"{DATA_PATH}/interactions.csv\")\n",
    "\n",
    "# Load vocab from dual-encoder step (important: consistent encoding)\n",
    "with open(\"../models/checkpoints/dual_vocab_v1.json\", \"r\") as f:\n",
    "    vocab = json.load(f)\n",
    "\n",
    "deal_vecs = np.load(\"../models/checkpoints/deal_vecs_v1.npy\")\n",
    "\n",
    "print(\"Loaded data + vocab + deal embeddings ✅\")\n",
    "print(\"deal_vecs:\", deal_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d83b51d1-8df4-4e21-8513-deb433b22ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def property_to_text(row):\n",
    "    return (\n",
    "        f\"{row['deal_type']} {row['property_type']} in {row['city']} {row['state']}. \"\n",
    "        f\"{int(row['beds'])} bed {row['baths']} bath, {int(row['sqft'])} sqft. \"\n",
    "        f\"Purchase {int(row['purchase_price'])}, ARV {int(row['arv'])}, \"\n",
    "        f\"Entry {int(row['entry_fee'])}, Payment {row['estimated_monthly_payment']}. \"\n",
    "        f\"Condition {row['condition']}, Occupancy {row['occupancy']}.\"\n",
    "    )\n",
    "\n",
    "properties[\"deal_text\"] = properties.apply(property_to_text, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41e558bf-10db-4c9a-8a91-02b0f9ee1fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    return re.findall(r\"[a-z0-9]+\", text.lower())\n",
    "\n",
    "# --- IMPORTANT: keep the dual vocab EXACTLY as saved ---\n",
    "dual_vocab = vocab  # this is loaded from dual_vocab_v1.json\n",
    "PAD_ID_DUAL = dual_vocab[\"<PAD>\"]\n",
    "UNK_ID_DUAL = dual_vocab[\"<UNK>\"]\n",
    "\n",
    "def encode_text_dual(text, max_len=48):\n",
    "    tokens = tokenize(text)\n",
    "    ids = [dual_vocab.get(w, UNK_ID_DUAL) for w in tokens][:max_len]\n",
    "    if len(ids) < max_len:\n",
    "        ids += [PAD_ID_DUAL] * (max_len - len(ids))\n",
    "    return np.array(ids, dtype=np.int64)\n",
    "\n",
    "# --- Create a separate vocab for cross encoder that includes <SEP> ---\n",
    "cross_vocab = copy.deepcopy(dual_vocab)\n",
    "if \"<SEP>\" not in cross_vocab:\n",
    "    cross_vocab[\"<SEP>\"] = len(cross_vocab)\n",
    "\n",
    "PAD_ID = cross_vocab[\"<PAD>\"]\n",
    "UNK_ID = cross_vocab[\"<UNK>\"]\n",
    "SEP_ID = cross_vocab[\"<SEP>\"]\n",
    "\n",
    "def encode_pair_cross(query_text, deal_text, max_len=96):\n",
    "    q_ids = [cross_vocab.get(w, UNK_ID) for w in tokenize(query_text)]\n",
    "    d_ids = [cross_vocab.get(w, UNK_ID) for w in tokenize(deal_text)]\n",
    "\n",
    "    q_max = int(max_len * 0.45)\n",
    "    d_max = max_len - q_max - 1\n",
    "\n",
    "    q_ids = q_ids[:q_max]\n",
    "    d_ids = d_ids[:d_max]\n",
    "\n",
    "    ids = q_ids + [SEP_ID] + d_ids\n",
    "    if len(ids) < max_len:\n",
    "        ids += [PAD_ID] * (max_len - len(ids))\n",
    "\n",
    "    ids = np.array(ids, dtype=np.int64)\n",
    "    ids = np.clip(ids, 0, len(cross_vocab)-1)  # safety\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2efb2494-410b-463b-a73e-8ddbcffa797e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relevance\n",
      "0    99888\n",
      "2    37625\n",
      "1    37436\n",
      "3    25051\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Keep labels 0–3 as a 4-class classification problem\n",
    "train_df = interactions.sample(200000, random_state=7).copy()  # increase later if you want\n",
    "print(train_df[\"relevance\"].value_counts())\n",
    "\n",
    "query_text_map = queries.set_index(\"query_id\")[\"query_text\"].to_dict()\n",
    "deal_text_map = properties.set_index(\"property_id\")[\"deal_text\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c73ddff1-f995-4742-97cf-be79dcef0de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEncoderDataset(Dataset):\n",
    "    def __init__(self, df, query_text_map, deal_text_map, max_len=96):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.qmap = query_text_map\n",
    "        self.dmap = deal_text_map\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.loc[idx]\n",
    "        qid = int(row[\"query_id\"])\n",
    "        pid = int(row[\"property_id\"])\n",
    "        y = int(row[\"relevance\"])\n",
    "\n",
    "        q_text = self.qmap[qid]\n",
    "        d_text = self.dmap[pid]\n",
    "\n",
    "        x = encode_pair_cross(q_text, d_text, max_len=self.max_len)\n",
    "        return torch.tensor(x, dtype=torch.long), torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "dataset = CrossEncoderDataset(train_df, query_text_map, deal_text_map, max_len=96)\n",
    "loader = DataLoader(dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e48956e-4749-4812-8241-e1146702c177",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=128, hidden=128, pad_id=0):\n",
    "        super().__init__()\n",
    "        self.pad_id = pad_id\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_id)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(emb_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, 4)\n",
    "        )\n",
    "\n",
    "    def forward(self, token_ids):\n",
    "        x = self.emb(token_ids)  # (B,L,D)\n",
    "        mask = (token_ids != self.pad_id).float().unsqueeze(-1)\n",
    "        pooled = (x * mask).sum(dim=1) / mask.sum(dim=1).clamp(min=1.0)\n",
    "        return self.mlp(pooled)\n",
    "\n",
    "# IMPORTANT: vocab_size must match the encoder used in encode_pair_cross\n",
    "model = CrossEncoder(vocab_size=len(cross_vocab), emb_dim=128, hidden=128, pad_id=PAD_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45526926-e1d7-422a-bad4-a79ce7c14045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch X shape: torch.Size([256, 96])\n",
      "Batch y shape: torch.Size([256])\n",
      "Min token id: 0\n",
      "Max token id: 18145\n",
      "cross_vocab size: 18146\n",
      "PAD_ID: 0 UNK_ID: 1 SEP_ID: 18145\n"
     ]
    }
   ],
   "source": [
    "# --- DEBUG: check token ID ranges coming from the DataLoader ---\n",
    "batch_X, batch_y = next(iter(loader))\n",
    "print(\"Batch X shape:\", batch_X.shape)\n",
    "print(\"Batch y shape:\", batch_y.shape)\n",
    "print(\"Min token id:\", batch_X.min().item())\n",
    "print(\"Max token id:\", batch_X.max().item())\n",
    "\n",
    "print(\"cross_vocab size:\", len(cross_vocab))\n",
    "print(\"PAD_ID:\", PAD_ID, \"UNK_ID:\", UNK_ID, \"SEP_ID:\", SEP_ID)\n",
    "\n",
    "assert batch_X.max().item() < len(cross_vocab), (\n",
    "    f\"Found token id {batch_X.max().item()} but cross_vocab size is {len(cross_vocab)}.\\n\"\n",
    "    \"Your dataset encoding vocab and model vocab_size are mismatched.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e9371fe-bc8d-4382-b181-045275f49f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - loss=1.2327\n",
      "Epoch 2/3 - loss=1.2144\n",
      "Epoch 3/3 - loss=1.1777\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "EPOCHS = 3\n",
    "model.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for X, y in loader:\n",
    "        logits = model(X)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - loss={total_loss/len(loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30cb6615-0dd4-4b36-b7a4-06320c75b21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cross encoder ✅\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"../models/checkpoints\", exist_ok=True)\n",
    "torch.save(model.state_dict(), \"../models/checkpoints/cross_encoder_v1.pt\")\n",
    "print(\"Saved cross encoder ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bb50c6e-7a20-4a59-9f17-5a874e9d4131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dual encoder loaded successfully ✅\n"
     ]
    }
   ],
   "source": [
    "# Normalize deal vectors (safety)\n",
    "deal_vecs = deal_vecs / (np.linalg.norm(deal_vecs, axis=1, keepdims=True) + 1e-9)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=128, pad_id=0):\n",
    "        super().__init__()\n",
    "        self.pad_id = pad_id\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_id)\n",
    "\n",
    "    def forward(self, token_ids):\n",
    "        x = self.emb(token_ids)  # (B,L,D)\n",
    "        mask = (token_ids != self.pad_id).float().unsqueeze(-1)\n",
    "        summed = (x * mask).sum(dim=1)\n",
    "        denom = mask.sum(dim=1).clamp(min=1.0)\n",
    "        return summed / denom\n",
    "\n",
    "class DualEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=128, pad_id=0):\n",
    "        super().__init__()\n",
    "        self.query_encoder = TextEncoder(vocab_size, emb_dim, pad_id=pad_id)\n",
    "        self.deal_encoder = TextEncoder(vocab_size, emb_dim, pad_id=pad_id)\n",
    "\n",
    "dual = DualEncoder(vocab_size=len(dual_vocab), emb_dim=128, pad_id=PAD_ID_DUAL)\n",
    "\n",
    "state = torch.load(\"../models/checkpoints/dual_encoder_v1.pt\", map_location=\"cpu\")\n",
    "dual.load_state_dict(state, strict=True)\n",
    "dual.eval()\n",
    "\n",
    "MAX_LEN_DUAL = 48\n",
    "\n",
    "def retrieve_top_n(prompt: str, top_n: int = 50):\n",
    "    q_ids = torch.tensor(encode_text_dual(prompt, max_len=MAX_LEN_DUAL), dtype=torch.long).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        q_vec = dual.query_encoder(q_ids).cpu().numpy()\n",
    "\n",
    "    q_vec = q_vec / (np.linalg.norm(q_vec, axis=1, keepdims=True) + 1e-9)\n",
    "    sims = (deal_vecs @ q_vec.T).squeeze(1)\n",
    "    idx = np.argsort(-sims)[:top_n]\n",
    "    return idx, sims[idx]\n",
    "\n",
    "print(\"Dual encoder loaded successfully ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e856a54f-5d55-427d-aff9-649c6f1dc42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "MAX_LEN_CROSS = 96\n",
    "\n",
    "def rerank_with_cross(prompt: str, top_n: int = 50, top_k: int = 5):\n",
    "    idx, sims = retrieve_top_n(prompt, top_n=top_n)\n",
    "\n",
    "    # Build cross-encoder inputs\n",
    "    batch = []\n",
    "    for i in idx:\n",
    "        d_text = properties.iloc[i][\"deal_text\"]\n",
    "        batch.append(encode_pair_cross(prompt, d_text, max_len=MAX_LEN_CROSS))\n",
    "\n",
    "    X = torch.tensor(np.stack(batch), dtype=torch.long)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(X)                  # (N,4)\n",
    "        probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "    # Expected relevance = sum(class * prob)\n",
    "    expected_rel = (probs * np.array([0,1,2,3], dtype=np.float32)).sum(axis=1)\n",
    "\n",
    "    # Sort by expected relevance (descending)\n",
    "    order = np.argsort(-expected_rel)[:top_k]\n",
    "    final_idx = idx[order]\n",
    "\n",
    "    out = properties.iloc[final_idx].copy()\n",
    "    out[\"retrieval_sim\"] = sims[order]\n",
    "    out[\"rerank_score\"] = expected_rel[order]\n",
    "\n",
    "    cols = [\"property_id\",\"deal_type\",\"city\",\"state\",\"beds\",\"baths\",\"sqft\",\n",
    "            \"purchase_price\",\"arv\",\"entry_fee\",\"estimated_monthly_payment\",\n",
    "            \"retrieval_sim\",\"rerank_score\"]\n",
    "    return out[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3332b933-65df-447f-967f-509a5ee2c205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_id</th>\n",
       "      <th>deal_type</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>sqft</th>\n",
       "      <th>purchase_price</th>\n",
       "      <th>arv</th>\n",
       "      <th>entry_fee</th>\n",
       "      <th>estimated_monthly_payment</th>\n",
       "      <th>retrieval_sim</th>\n",
       "      <th>rerank_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>DSCR Carryback</td>\n",
       "      <td>Tempe</td>\n",
       "      <td>AZ</td>\n",
       "      <td>3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1195</td>\n",
       "      <td>227163.0</td>\n",
       "      <td>254263.0</td>\n",
       "      <td>12881.0</td>\n",
       "      <td>1630.65</td>\n",
       "      <td>0.220366</td>\n",
       "      <td>2.052900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4783</th>\n",
       "      <td>4784</td>\n",
       "      <td>Seller Finance</td>\n",
       "      <td>Fairview</td>\n",
       "      <td>MO</td>\n",
       "      <td>5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2770</td>\n",
       "      <td>533648.0</td>\n",
       "      <td>836136.0</td>\n",
       "      <td>5737.0</td>\n",
       "      <td>4283.82</td>\n",
       "      <td>0.271495</td>\n",
       "      <td>1.781545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14470</th>\n",
       "      <td>14471</td>\n",
       "      <td>Seller Finance</td>\n",
       "      <td>Madison</td>\n",
       "      <td>OK</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2835</td>\n",
       "      <td>195159.0</td>\n",
       "      <td>313156.0</td>\n",
       "      <td>8917.0</td>\n",
       "      <td>1866.68</td>\n",
       "      <td>0.226320</td>\n",
       "      <td>1.586047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8762</th>\n",
       "      <td>8763</td>\n",
       "      <td>Seller Finance</td>\n",
       "      <td>Jonesboro</td>\n",
       "      <td>GA</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2076</td>\n",
       "      <td>136956.0</td>\n",
       "      <td>214401.0</td>\n",
       "      <td>27338.0</td>\n",
       "      <td>1032.35</td>\n",
       "      <td>0.209417</td>\n",
       "      <td>1.392262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10895</th>\n",
       "      <td>10896</td>\n",
       "      <td>Seller Finance</td>\n",
       "      <td>Memphis</td>\n",
       "      <td>TN</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1724</td>\n",
       "      <td>225272.0</td>\n",
       "      <td>350105.0</td>\n",
       "      <td>20315.0</td>\n",
       "      <td>1765.02</td>\n",
       "      <td>0.210427</td>\n",
       "      <td>1.380082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       property_id       deal_type       city state  beds  baths  sqft  \\\n",
       "34              35  DSCR Carryback      Tempe    AZ     3    2.5  1195   \n",
       "4783          4784  Seller Finance   Fairview    MO     5    3.5  2770   \n",
       "14470        14471  Seller Finance    Madison    OK     4    3.0  2835   \n",
       "8762          8763  Seller Finance  Jonesboro    GA     3    3.0  2076   \n",
       "10895        10896  Seller Finance    Memphis    TN     2    2.5  1724   \n",
       "\n",
       "       purchase_price       arv  entry_fee  estimated_monthly_payment  \\\n",
       "34           227163.0  254263.0    12881.0                    1630.65   \n",
       "4783         533648.0  836136.0     5737.0                    4283.82   \n",
       "14470        195159.0  313156.0     8917.0                    1866.68   \n",
       "8762         136956.0  214401.0    27338.0                    1032.35   \n",
       "10895        225272.0  350105.0    20315.0                    1765.02   \n",
       "\n",
       "       retrieval_sim  rerank_score  \n",
       "34          0.220366      2.052900  \n",
       "4783        0.271495      1.781545  \n",
       "14470       0.226320      1.586047  \n",
       "8762        0.209417      1.392262  \n",
       "10895       0.210427      1.380082  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Looking for 3 bed deals under 350k, entry under 20k, payment under 2500 in Phoenix AZ\"\n",
    "rerank_with_cross(prompt, top_n=50, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae267b54-17b5-4cde-ba57-62a162300ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_deals(df):\n",
    "    lines = []\n",
    "    for i, row in df.reset_index(drop=True).iterrows():\n",
    "        lines.append(\n",
    "            f\"{i+1}) {row['deal_type']} | {row['beds']}bd/{row['baths']}ba | {row['city']}, {row['state']} | \"\n",
    "            f\"Buy ${int(row['purchase_price']):,} | ARV ${int(row['arv']):,} | Entry ${int(row['entry_fee']):,} | \"\n",
    "            f\"Pay ${float(row['estimated_monthly_payment']):,.0f} | Score {row['rerank_score']:.2f}\"\n",
    "        )\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "while True:\n",
    "    user = input(\"\\nYou: \").strip()\n",
    "    if user.lower() in [\"quit\", \"exit\"]:\n",
    "        print(\"Bot: Bye!\")\n",
    "        break\n",
    "\n",
    "    deals = rerank_with_cross(user, top_n=50, top_k=5)\n",
    "    print(\"\\nBot: Here are the top 5 deals that match your criteria:\\n\")\n",
    "    print(format_deals(deals))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
