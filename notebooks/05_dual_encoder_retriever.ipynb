{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a52cb358-f178-4af3-949e-f394f6e3a9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56b0c40c-de2e-4de4-bbc4-39ac8e324e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 16) (15000, 27) (480000, 4)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../data/nexkey_synthetic_dataset_v1\"\n",
    "queries = pd.read_csv(f\"{DATA_PATH}/queries.csv\")\n",
    "properties = pd.read_csv(f\"{DATA_PATH}/properties.csv\")\n",
    "interactions = pd.read_csv(f\"{DATA_PATH}/interactions.csv\")\n",
    "\n",
    "print(queries.shape, properties.shape, interactions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a28d6f8-6c97-41a3-a728-1a3c16318bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_id</th>\n",
       "      <th>deal_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Subto Single Family in Raleigh NC. 4 bed 1.0 b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Hybrid Single Family in Sacramento CA. 5 bed 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cash Condo in Charleston SC. 4 bed 2.5 bath, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Subto Manufactured in Greenville AL. 4 bed 2.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Seller Finance Single Family in Fairview AL. 3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   property_id                                          deal_text\n",
       "0            1  Subto Single Family in Raleigh NC. 4 bed 1.0 b...\n",
       "1            2  Hybrid Single Family in Sacramento CA. 5 bed 1...\n",
       "2            3  Cash Condo in Charleston SC. 4 bed 2.5 bath, 3...\n",
       "3            4  Subto Manufactured in Greenville AL. 4 bed 2.0...\n",
       "4            5  Seller Finance Single Family in Fairview AL. 3..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def property_to_text(row):\n",
    "    return (\n",
    "        f\"{row['deal_type']} {row['property_type']} in {row['city']} {row['state']}. \"\n",
    "        f\"{int(row['beds'])} bed {row['baths']} bath, {int(row['sqft'])} sqft. \"\n",
    "        f\"Purchase {int(row['purchase_price'])}, ARV {int(row['arv'])}, \"\n",
    "        f\"Entry {int(row['entry_fee'])}, Payment {row['estimated_monthly_payment']}. \"\n",
    "        f\"Condition {row['condition']}, Occupancy {row['occupancy']}.\"\n",
    "    )\n",
    "\n",
    "properties[\"deal_text\"] = properties.apply(property_to_text, axis=1)\n",
    "properties[[\"property_id\", \"deal_text\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "053cfbbc-e902-482f-97eb-ddd1352eebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only strong positives\n",
    "pos = interactions[interactions[\"relevance\"] >= 2][[\"query_id\", \"property_id\"]].copy()\n",
    "\n",
    "# For speed while learning, sample a subset (increase later)\n",
    "pos = pos.sample(120000, random_state=7)\n",
    "\n",
    "# Build a quick lookup: query_id -> set of positive property_ids\n",
    "pos_map = pos.groupby(\"query_id\")[\"property_id\"].apply(set).to_dict()\n",
    "\n",
    "all_property_ids = properties[\"property_id\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84066146-c658-4045-910d-fa8c6694e857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 18145\n"
     ]
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    # lowercase + keep words/numbers\n",
    "    return re.findall(r\"[a-z0-9]+\", text.lower())\n",
    "\n",
    "# Build vocab from a sample for speed\n",
    "VOCAB_SIZE = 30000\n",
    "word_counts = {}\n",
    "\n",
    "for t in pd.concat([queries[\"query_text\"].sample(5000, random_state=7),\n",
    "                    properties[\"deal_text\"].sample(5000, random_state=7)]):\n",
    "    for w in tokenize(t):\n",
    "        word_counts[w] = word_counts.get(w, 0) + 1\n",
    "\n",
    "# Keep most common words\n",
    "vocab = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "for w, _ in sorted(word_counts.items(), key=lambda x: -x[1])[:VOCAB_SIZE-2]:\n",
    "    vocab[w] = len(vocab)\n",
    "\n",
    "def encode(text, max_len=48):\n",
    "    tokens = tokenize(text)\n",
    "    ids = [vocab.get(w, vocab[\"<UNK>\"]) for w in tokens][:max_len]\n",
    "    if len(ids) < max_len:\n",
    "        ids += [vocab[\"<PAD>\"]] * (max_len - len(ids))\n",
    "    return np.array(ids, dtype=np.int64)\n",
    "\n",
    "print(\"Vocab size:\", len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d39e8dc5-f23a-49cb-80d8-c3b7941c86b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairDataset(Dataset):\n",
    "    def __init__(self, pos_df, queries_df, properties_df, pos_map, all_property_ids, max_len=48):\n",
    "        self.pos_df = pos_df.reset_index(drop=True)\n",
    "        self.queries = queries_df.set_index(\"query_id\")\n",
    "        self.props = properties_df.set_index(\"property_id\")\n",
    "        self.pos_map = pos_map\n",
    "        self.all_pids = all_property_ids\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pos_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        qid = int(self.pos_df.loc[idx, \"query_id\"])\n",
    "        pos_pid = int(self.pos_df.loc[idx, \"property_id\"])\n",
    "\n",
    "        q_text = self.queries.loc[qid, \"query_text\"]\n",
    "        pos_text = self.props.loc[pos_pid, \"deal_text\"]\n",
    "\n",
    "        # Sample a negative property not in positives\n",
    "        positives = self.pos_map.get(qid, set())\n",
    "        neg_pid = int(np.random.choice(self.all_pids))\n",
    "        while neg_pid in positives:\n",
    "            neg_pid = int(np.random.choice(self.all_pids))\n",
    "        neg_text = self.props.loc[neg_pid, \"deal_text\"]\n",
    "\n",
    "        q_ids = encode(q_text, self.max_len)\n",
    "        pos_ids = encode(pos_text, self.max_len)\n",
    "        neg_ids = encode(neg_text, self.max_len)\n",
    "\n",
    "        return (\n",
    "            torch.tensor(q_ids),\n",
    "            torch.tensor(pos_ids),\n",
    "            torch.tensor(neg_ids),\n",
    "        )\n",
    "\n",
    "dataset = PairDataset(pos, queries, properties, pos_map, all_property_ids)\n",
    "loader = DataLoader(dataset, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66799078-7de6-442b-9da9-ceb024c03bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=128):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "\n",
    "    def forward(self, token_ids):\n",
    "        # token_ids: (B, L)\n",
    "        x = self.emb(token_ids)  # (B, L, D)\n",
    "\n",
    "        # mean pooling ignoring PAD\n",
    "        mask = (token_ids != 0).float().unsqueeze(-1)  # (B, L, 1)\n",
    "        summed = (x * mask).sum(dim=1)                 # (B, D)\n",
    "        denom = mask.sum(dim=1).clamp(min=1.0)         # (B, 1)\n",
    "        return summed / denom\n",
    "\n",
    "class DualEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim=128):\n",
    "        super().__init__()\n",
    "        self.query_encoder = TextEncoder(vocab_size, emb_dim)\n",
    "        self.deal_encoder = TextEncoder(vocab_size, emb_dim)\n",
    "\n",
    "    def forward(self, q, pos, neg):\n",
    "        q_vec = self.query_encoder(q)\n",
    "        pos_vec = self.deal_encoder(pos)\n",
    "        neg_vec = self.deal_encoder(neg)\n",
    "        return q_vec, pos_vec, neg_vec\n",
    "\n",
    "model = DualEncoder(vocab_size=len(vocab), emb_dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32f33e96-3412-46a1-b65d-a7f8b6f6b86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, loss=0.1756\n",
      "Epoch 2/3, loss=0.1266\n",
      "Epoch 3/3, loss=0.0782\n"
     ]
    }
   ],
   "source": [
    "def cosine_sim(a, b):\n",
    "    a = nn.functional.normalize(a, dim=1)\n",
    "    b = nn.functional.normalize(b, dim=1)\n",
    "    return (a * b).sum(dim=1)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "EPOCHS = 3\n",
    "model.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for q_ids, pos_ids, neg_ids in loader:\n",
    "        q_vec, pos_vec, neg_vec = model(q_ids, pos_ids, neg_ids)\n",
    "\n",
    "        pos_sim = cosine_sim(q_vec, pos_vec)\n",
    "        neg_sim = cosine_sim(q_vec, neg_vec)\n",
    "\n",
    "        # Margin ranking loss: pos should be > neg by margin\n",
    "        loss = torch.relu(0.2 - (pos_sim - neg_sim)).mean()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, loss={total_loss/len(loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6f4b533-0d4f-453c-8496-1ee20a93b884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model + vocab ✅\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "os.makedirs(\"../models/checkpoints\", exist_ok=True)\n",
    "\n",
    "# Save model weights\n",
    "torch.save(model.state_dict(), \"../models/checkpoints/dual_encoder_v1.pt\")\n",
    "\n",
    "# Save vocab so encoding is consistent later\n",
    "with open(\"../models/checkpoints/dual_vocab_v1.json\", \"w\") as f:\n",
    "    json.dump(vocab, f)\n",
    "\n",
    "print(\"Saved model + vocab ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d101c95-2362-47f1-9b16-10c8c250175c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DualEncoder(\n",
       "  (query_encoder): TextEncoder(\n",
       "    (emb): Embedding(18145, 128, padding_idx=0)\n",
       "  )\n",
       "  (deal_encoder): TextEncoder(\n",
       "    (emb): Embedding(18145, 128, padding_idx=0)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54b2d9a2-3a8e-49a2-afd2-5e4591ea66c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deal token matrix: torch.Size([15000, 48])\n",
      "Deal embeddings: (15000, 128)\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 48\n",
    "\n",
    "# Encode all deal texts into token IDs\n",
    "deal_token_ids = np.stack([encode(t, MAX_LEN) for t in properties[\"deal_text\"].values])\n",
    "deal_token_ids = torch.tensor(deal_token_ids, dtype=torch.long)\n",
    "\n",
    "print(\"Deal token matrix:\", deal_token_ids.shape)\n",
    "\n",
    "with torch.no_grad():\n",
    "    deal_vecs = model.deal_encoder(deal_token_ids).cpu().numpy()\n",
    "\n",
    "# Normalize for cosine similarity\n",
    "deal_vecs = deal_vecs / (np.linalg.norm(deal_vecs, axis=1, keepdims=True) + 1e-9)\n",
    "\n",
    "print(\"Deal embeddings:\", deal_vecs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c29b7abe-9549-4861-a3dd-d1881a74e0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved deal embeddings ✅\n"
     ]
    }
   ],
   "source": [
    "np.save(\"../models/checkpoints/deal_vecs_v1.npy\", deal_vecs)\n",
    "properties[[\"property_id\"]].to_csv(\"../models/checkpoints/deal_ids_v1.csv\", index=False)\n",
    "\n",
    "print(\"Saved deal embeddings ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39941ed4-711a-409a-9fe5-c76572149a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_top_k(prompt: str, top_k: int = 5):\n",
    "    # 1) Encode query\n",
    "    q_ids = torch.tensor(encode(prompt, MAX_LEN), dtype=torch.long).unsqueeze(0)  # (1, L)\n",
    "\n",
    "    # 2) Embed query\n",
    "    with torch.no_grad():\n",
    "        q_vec = model.query_encoder(q_ids).cpu().numpy()  # (1, D)\n",
    "\n",
    "    # 3) Normalize\n",
    "    q_vec = q_vec / (np.linalg.norm(q_vec, axis=1, keepdims=True) + 1e-9)\n",
    "\n",
    "    # 4) Cosine similarity = dot product of normalized vectors\n",
    "    sims = (deal_vecs @ q_vec.T).squeeze(1)  # (num_deals,)\n",
    "\n",
    "    # 5) Get top indices\n",
    "    top_idx = np.argsort(-sims)[:top_k]\n",
    "\n",
    "    # 6) Return top deals with similarity score\n",
    "    result = properties.iloc[top_idx].copy()\n",
    "    result[\"similarity\"] = sims[top_idx]\n",
    "    cols = [\"property_id\", \"deal_type\", \"city\", \"state\", \"beds\", \"baths\", \"sqft\",\n",
    "            \"purchase_price\", \"arv\", \"entry_fee\", \"estimated_monthly_payment\", \"similarity\"]\n",
    "    return result[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "526cfc98-7352-4cec-a5d2-b44c906cb0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>property_id</th>\n",
       "      <th>deal_type</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>beds</th>\n",
       "      <th>baths</th>\n",
       "      <th>sqft</th>\n",
       "      <th>purchase_price</th>\n",
       "      <th>arv</th>\n",
       "      <th>entry_fee</th>\n",
       "      <th>estimated_monthly_payment</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4783</th>\n",
       "      <td>4784</td>\n",
       "      <td>Seller Finance</td>\n",
       "      <td>Fairview</td>\n",
       "      <td>MO</td>\n",
       "      <td>5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2770</td>\n",
       "      <td>533648.0</td>\n",
       "      <td>836136.0</td>\n",
       "      <td>5737.0</td>\n",
       "      <td>4283.82</td>\n",
       "      <td>0.271495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11510</th>\n",
       "      <td>11511</td>\n",
       "      <td>Subto</td>\n",
       "      <td>Tempe</td>\n",
       "      <td>AZ</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2332</td>\n",
       "      <td>213698.0</td>\n",
       "      <td>375438.0</td>\n",
       "      <td>6652.0</td>\n",
       "      <td>2180.93</td>\n",
       "      <td>0.270117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14910</th>\n",
       "      <td>14911</td>\n",
       "      <td>Seller Finance</td>\n",
       "      <td>Greenville</td>\n",
       "      <td>UT</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2304</td>\n",
       "      <td>327540.0</td>\n",
       "      <td>556610.0</td>\n",
       "      <td>23087.0</td>\n",
       "      <td>2764.35</td>\n",
       "      <td>0.268693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5098</th>\n",
       "      <td>5099</td>\n",
       "      <td>Wrap</td>\n",
       "      <td>Greenville</td>\n",
       "      <td>OK</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2393</td>\n",
       "      <td>244459.0</td>\n",
       "      <td>398621.0</td>\n",
       "      <td>12619.0</td>\n",
       "      <td>1627.17</td>\n",
       "      <td>0.255297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8711</th>\n",
       "      <td>8712</td>\n",
       "      <td>Subto</td>\n",
       "      <td>Tempe</td>\n",
       "      <td>AZ</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2378</td>\n",
       "      <td>443778.0</td>\n",
       "      <td>532760.0</td>\n",
       "      <td>8586.0</td>\n",
       "      <td>4416.39</td>\n",
       "      <td>0.255227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       property_id       deal_type        city state  beds  baths  sqft  \\\n",
       "4783          4784  Seller Finance    Fairview    MO     5    3.5  2770   \n",
       "11510        11511           Subto       Tempe    AZ     2    4.0  2332   \n",
       "14910        14911  Seller Finance  Greenville    UT     3    2.0  2304   \n",
       "5098          5099            Wrap  Greenville    OK     2    2.5  2393   \n",
       "8711          8712           Subto       Tempe    AZ     4    2.0  2378   \n",
       "\n",
       "       purchase_price       arv  entry_fee  estimated_monthly_payment  \\\n",
       "4783         533648.0  836136.0     5737.0                    4283.82   \n",
       "11510        213698.0  375438.0     6652.0                    2180.93   \n",
       "14910        327540.0  556610.0    23087.0                    2764.35   \n",
       "5098         244459.0  398621.0    12619.0                    1627.17   \n",
       "8711         443778.0  532760.0     8586.0                    4416.39   \n",
       "\n",
       "       similarity  \n",
       "4783     0.271495  \n",
       "11510    0.270117  \n",
       "14910    0.268693  \n",
       "5098     0.255297  \n",
       "8711     0.255227  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_prompt = \"Looking for 3 bed deals under 350k, entry under 20k, payment under 2500 in Phoenix AZ\"\n",
    "retrieve_top_k(user_prompt, top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77c1de00-7f5a-470e-9f25-1db0cb212baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval queries: 500\n"
     ]
    }
   ],
   "source": [
    "# Build ground truth: for each query, which property_ids are relevant (>=2)\n",
    "gt = interactions[interactions[\"relevance\"] >= 2].groupby(\"query_id\")[\"property_id\"].apply(set).to_dict()\n",
    "\n",
    "# Sample queries for evaluation (speed)\n",
    "eval_query_ids = list(gt.keys())\n",
    "eval_query_ids = np.random.choice(eval_query_ids, size=500, replace=False)\n",
    "\n",
    "print(\"Eval queries:\", len(eval_query_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1e723dc-12b3-4c2a-988c-17d3e6523717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(recommended_pids, relevant_pids, k):\n",
    "    rec_k = set(recommended_pids[:k])\n",
    "    return 1.0 if len(rec_k.intersection(relevant_pids)) > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b5b34f3-31fb-45cf-8c45-cc85985d4631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 0.0180\n",
      "Recall@5: 0.0880\n",
      "Recall@10: 0.1580\n"
     ]
    }
   ],
   "source": [
    "Ks = [1, 5, 10]\n",
    "recalls = {k: [] for k in Ks}\n",
    "\n",
    "for qid in eval_query_ids:\n",
    "    prompt = queries.loc[queries[\"query_id\"] == qid, \"query_text\"].iloc[0]\n",
    "    relevant = gt[qid]\n",
    "\n",
    "    # retrieve top 10\n",
    "    rec_df = retrieve_top_k(prompt, top_k=10)\n",
    "    rec_pids = rec_df[\"property_id\"].tolist()\n",
    "\n",
    "    for k in Ks:\n",
    "        recalls[k].append(recall_at_k(rec_pids, relevant, k))\n",
    "\n",
    "for k in Ks:\n",
    "    print(f\"Recall@{k}: {np.mean(recalls[k]):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
